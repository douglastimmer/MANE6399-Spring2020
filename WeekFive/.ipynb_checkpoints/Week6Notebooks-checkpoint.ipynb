{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week Six\n",
    "\n",
    "## Multiple Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Example 1\n",
    "\n",
    "## iPython.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Top Heading in Output window</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Any valid HTML code contained withing the quotes&nbsp;</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>I have used mainly for adding headers to output windows&nbsp:</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Latex\n",
    "#\n",
    "display(HTML(\"<h1>Top Heading in Output window</h1>\"))\n",
    "display(HTML(\"<p>Any valid HTML code contained withing the quotes&nbsp;</p>\"))\n",
    "display(HTML(\"<p>I have used mainly for adding headers to output windows&nbsp:</p>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$F(z)=\\int_{-\\infty}^zf(x)=\\int_{-\\infty}^z\\frac{1}{\\sqrt{2\\pi}}\\left(\\frac{-x}{2}\\right)^2\\,dx=\\Phi(z)$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Latex\n",
    "#\n",
    "display(Latex(r\"\"\"$F(z)=\\int_{-\\infty}^zf(x)=\\int_{-\\infty}^z\\frac{1}{\\sqrt{2\\pi}}\\left(\\frac{-x}{2}\\right)^2\\,dx=\\Phi(z)$\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Example 2\n",
    "\n",
    "## Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Concrete Data set</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Descriptive Statistics</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>flyAsh</th>\n",
       "      <th>water</th>\n",
       "      <th>plasticizer</th>\n",
       "      <th>coarse</th>\n",
       "      <th>fine</th>\n",
       "      <th>age</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.165631</td>\n",
       "      <td>73.895485</td>\n",
       "      <td>54.187136</td>\n",
       "      <td>181.566359</td>\n",
       "      <td>6.203112</td>\n",
       "      <td>972.918592</td>\n",
       "      <td>773.578883</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.507142</td>\n",
       "      <td>86.279104</td>\n",
       "      <td>63.996469</td>\n",
       "      <td>21.355567</td>\n",
       "      <td>5.973492</td>\n",
       "      <td>77.753818</td>\n",
       "      <td>80.175427</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.331808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.707115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.350000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.510000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.442774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.270000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.160000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.136287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.599225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cement         slag       flyAsh        water  plasticizer  \\\n",
       "count  1030.000000  1030.000000  1030.000000  1030.000000  1030.000000   \n",
       "mean    281.165631    73.895485    54.187136   181.566359     6.203112   \n",
       "std     104.507142    86.279104    63.996469    21.355567     5.973492   \n",
       "min     102.000000     0.000000     0.000000   121.750000     0.000000   \n",
       "25%     192.375000     0.000000     0.000000   164.900000     0.000000   \n",
       "50%     272.900000    22.000000     0.000000   185.000000     6.350000   \n",
       "75%     350.000000   142.950000   118.270000   192.000000    10.160000   \n",
       "max     540.000000   359.400000   200.100000   247.000000    32.200000   \n",
       "\n",
       "            coarse         fine          age     strength  \n",
       "count  1030.000000  1030.000000  1030.000000  1030.000000  \n",
       "mean    972.918592   773.578883    45.662136    35.817836  \n",
       "std      77.753818    80.175427    63.169912    16.705679  \n",
       "min     801.000000   594.000000     1.000000     2.331808  \n",
       "25%     932.000000   730.950000     7.000000    23.707115  \n",
       "50%     968.000000   779.510000    28.000000    34.442774  \n",
       "75%    1029.400000   824.000000    56.000000    46.136287  \n",
       "max    1145.000000   992.600000   365.000000    82.599225  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Latex\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as sm\n",
    "display(HTML(\"<h2>Concrete Data set</h2>\"))\n",
    "df = pd.read_excel('Concrete_Data.xls', sheetname='Sheet1')\n",
    "\n",
    "display(HTML(\"<h3>Descriptive Statistics</h3>\"))\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Regression Analysis</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    strength  cement   slag  flyAsh  water  plasticizer  coarse   fine  age\n",
      "0  79.986111   540.0    0.0     0.0  162.0          2.5  1040.0  676.0   28\n",
      "1  61.887366   540.0    0.0     0.0  162.0          2.5  1055.0  676.0   28\n",
      "2  40.269535   332.5  142.5     0.0  228.0          0.0   932.0  594.0  270\n",
      "3  41.052780   332.5  142.5     0.0  228.0          0.0   932.0  594.0  365\n",
      "4  44.296075   198.6  132.4     0.0  192.0          0.0   978.4  825.5  360\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               strength   R-squared:                       0.615\n",
      "Model:                            OLS   Adj. R-squared:                  0.612\n",
      "Method:                 Least Squares   F-statistic:                     204.3\n",
      "Date:                Mon, 19 Feb 2018   Prob (F-statistic):          6.76e-206\n",
      "Time:                        16:28:11   Log-Likelihood:                -3869.0\n",
      "No. Observations:                1030   AIC:                             7756.\n",
      "Df Residuals:                    1021   BIC:                             7800.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept     -23.1638     26.588     -0.871      0.384     -75.338      29.010\n",
      "cement          0.1198      0.008     14.110      0.000       0.103       0.136\n",
      "slag            0.1038      0.010     10.245      0.000       0.084       0.124\n",
      "flyAsh          0.0879      0.013      6.988      0.000       0.063       0.113\n",
      "water          -0.1503      0.040     -3.741      0.000      -0.229      -0.071\n",
      "plasticizer     0.2907      0.093      3.110      0.002       0.107       0.474\n",
      "coarse          0.0180      0.009      1.919      0.055      -0.000       0.036\n",
      "fine            0.0202      0.011      1.883      0.060      -0.001       0.041\n",
      "age             0.1142      0.005     21.046      0.000       0.104       0.125\n",
      "==============================================================================\n",
      "Omnibus:                        5.379   Durbin-Watson:                   1.281\n",
      "Prob(Omnibus):                  0.068   Jarque-Bera (JB):                5.305\n",
      "Skew:                          -0.174   Prob(JB):                       0.0705\n",
      "Kurtosis:                       3.045   Cond. No.                     1.06e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.06e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "display(HTML(\"<h3>Regression Analysis</h3>\"))\n",
    "# clean up data frame\n",
    "df.dropna() # drop missing values\n",
    "df=df[['strength','cement','slag','flyAsh','water','plasticizer','coarse','fine','age']].dropna() # reordered dataframe with y first\n",
    "print(df.head())\n",
    "model1 = sm.ols(formula='strength~cement+slag+flyAsh+water+plasticizer+coarse+fine+age',data=df)\n",
    "fitted1 = model1.fit()\n",
    "print(fitted1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Anova Table</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Source      df  Sum of Squares   Mean Square F Statistic       p value\n",
      "0  Regression     8.0   110428.156817  22093.108958     204.269  6.76158e-206\n",
      "1       Error  1021.0   176744.871661    108.156863                          \n",
      "2       Total  1029.0   287173.028478    279.079717                          \n"
     ]
    }
   ],
   "source": [
    "display(HTML(\"<h3>Anova Table</h3>\"))\n",
    "\n",
    "def prepANOVAtable(model):\n",
    "    tmp={'Source':['Regression','Error','Total'],'df': [model.df_model,model.df_resid,model.df_model+model.df_resid],'Sum of Squares':[model.ssr,model.ess,model.ssr+model.ess],'Mean Square':[model.mse_model,model.mse_resid,model.mse_total],'F Statistic':[model.fvalue,'',''],'p value':[model.f_pvalue,'','']}\n",
    "    anova_df=pd.DataFrame(data=tmp)\n",
    "    anova_df=anova_df[['Source','df','Sum of Squares','Mean Square','F Statistic','p value']]\n",
    "    return(anova_df)\n",
    "anova1_df=prepANOVAtable(fitted1)\n",
    "print(anova1_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Example 3\n",
    "\n",
    "## Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Variance Inflation Factors</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>VIF Factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cement</td>\n",
       "      <td>15.468620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>slag</td>\n",
       "      <td>3.330359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flyAsh</td>\n",
       "      <td>4.148893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>water</td>\n",
       "      <td>82.150840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plasticizer</td>\n",
       "      <td>5.472391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>coarse</td>\n",
       "      <td>84.959460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fine</td>\n",
       "      <td>72.795397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>age</td>\n",
       "      <td>1.699430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Variable  VIF Factor\n",
       "0       cement   15.468620\n",
       "1         slag    3.330359\n",
       "2       flyAsh    4.148893\n",
       "3        water   82.150840\n",
       "4  plasticizer    5.472391\n",
       "5       coarse   84.959460\n",
       "6         fine   72.795397\n",
       "7          age    1.699430"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "display(HTML(\"<h2>Variance Inflation Factors</h2>\"))\n",
    "# drop missing values and create array of x variables\n",
    "df=df.dropna()\n",
    "exog1=df.drop('strength',axis=1)\n",
    "# calculate VIF and save in data frame\n",
    "vif1=pd.DataFrame()\n",
    "vif1[\"VIF Factor\"]=[variance_inflation_factor(exog1.values,i) for i in range(exog1.shape[1])]\n",
    "vif1[\"Variable\"]=exog1.columns\n",
    "vif1=vif1[[\"Variable\",\"VIF Factor\"]]\n",
    "vif1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Example 4\n",
    "\n",
    "## Partial F Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Partial F Test</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3> Full Model</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Source      df  Sum of Squares   Mean Square F Statistic       p value\n",
      "0  Regression     8.0   110428.156817  22093.108958     204.269  6.76158e-206\n",
      "1       Error  1021.0   176744.871661    108.156863                          \n",
      "2       Total  1029.0   287173.028478    279.079717                          \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Reduced Model</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Source      df  Sum of Squares   Mean Square F Statistic       p value\n",
      "0  Regression     6.0   110855.967752  29386.176788     271.181  1.77977e-207\n",
      "1       Error  1023.0   176317.060726    108.363605                          \n",
      "2       Total  1029.0   287173.028478    279.079717                          \n"
     ]
    }
   ],
   "source": [
    "display(HTML(\"<h2>Partial F Test</h2>\"))\n",
    "display(HTML(\"<h3> Full Model</h3>\"))\n",
    "# full model\n",
    "print(anova1_df)\n",
    "# reduced model\n",
    "display(HTML(\"<h3>Reduced Model</h3>\"))\n",
    "model2 = sm.ols(formula='strength~cement+slag+flyAsh+water+plasticizer+age',data=df)\n",
    "fitted2 = model2.fit()\n",
    "anova2_df=prepANOVAtable(fitted2)\n",
    "print(anova2_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Example 5\n",
    "\n",
    "## Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Forward Variable Selection"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href='https://planspace.org/20150423-forward_selection_with_statsmodels/'>Source</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strength ~ cement + plasticizer + age + slag + water + flyAsh + 1\n",
      "0.611710925737\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "display(HTML(\"<h2>Forward Variable Selection\"))\n",
    "display(HTML(\"<a href='https://planspace.org/20150423-forward_selection_with_statsmodels/'>Source</a>\"))\n",
    "def forward_selection(data, response):\n",
    "    \"\"\"Linear model designed by forward selection.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas DataFrame with all possible predictors and response\n",
    "\n",
    "    response: string, name of response column in data\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    model: an \"optimal\" fitted statsmodels linear model\n",
    "           with an intercept\n",
    "           selected by forward selection\n",
    "           evaluated by adjusted R-squared\n",
    "    \"\"\"\n",
    "    remaining = set(data.columns)\n",
    "    remaining.remove(response)\n",
    "    selected = []\n",
    "    current_score, best_new_score = 0.0, 0.0\n",
    "    while remaining and current_score == best_new_score:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in remaining:\n",
    "            formula = \"{} ~ {} + 1\".format(response,\n",
    "                                           ' + '.join(selected + [candidate]))\n",
    "            score = smf.ols(formula, data).fit().rsquared_adj\n",
    "            scores_with_candidates.append((score, candidate))\n",
    "        scores_with_candidates.sort()\n",
    "        best_new_score, best_candidate = scores_with_candidates.pop()\n",
    "        if current_score < best_new_score:\n",
    "            remaining.remove(best_candidate)\n",
    "            selected.append(best_candidate)\n",
    "            current_score = best_new_score\n",
    "    formula = \"{} ~ {} + 1\".format(response,\n",
    "                                   ' + '.join(selected))\n",
    "    model = smf.ols(formula, data).fit()\n",
    "    return model\n",
    "forward=forward_selection(df,'strength')\n",
    "print(forward.model.formula)\n",
    "print(forward.rsquared_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Example 6\n",
    "\n",
    "## Backwards Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Example 7\n",
    "\n",
    "## Stepwise Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fwn285\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Step Variable Selection"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href='https://datascience.stackexchange.com/questions/24405/how-to-do-stepwise-regression-using-sklearn'>Source</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  strength                       with p-value 0.0\n",
      "Add  fine                           with p-value 6.90229e-60\n",
      "Add  water                          with p-value 2.43286e-19\n",
      "Add  coarse                         with p-value 1.04171e-24\n",
      "Drop fine                           with p-value 0.650579\n",
      "Add  slag                           with p-value 5.32403e-64\n",
      "Drop water                          with p-value 0.591642\n",
      "Add  plasticizer                    with p-value 0.0008551\n",
      "Drop slag                           with p-value 0.779371\n",
      "Add  flyAsh                         with p-value 2.5496e-19\n",
      "Drop coarse                         with p-value 0.122845\n",
      "Add  slag                           with p-value 2.72804e-75\n",
      "Drop plasticizer                    with p-value 0.473062\n",
      "Add  fine                           with p-value 1.00431e-123\n",
      "Add  cement                         with p-value 5.30064e-07\n",
      "resulting features:\n",
      "['strength', 'flyAsh', 'slag', 'fine', 'cement']\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "display(HTML(\"<h2>Step Variable Selection\"))\n",
    "display(HTML(\"<a href='https://datascience.stackexchange.com/questions/24405/how-to-do-stepwise-regression-using-sklearn'>Source</a>\"))\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.argmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "X=df\n",
    "y=df[\"strength\"]\n",
    "result = stepwise_selection(X, y)\n",
    "\n",
    "print('resulting features:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Example 8\n",
    "\n",
    "## All Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Best Subsets"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href='http://songhuiming.github.io/pages/2015/09/26/best-subset-regression-in-python/'>Source</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating model with inputs (0,), adjusted R^2 is 0.247106\n",
      "evaluating model with inputs (1,), adjusted R^2 is 0.017223\n",
      "evaluating model with inputs (2,), adjusted R^2 is 0.010222\n",
      "evaluating model with inputs (3,), adjusted R^2 is 0.082985\n",
      "evaluating model with inputs (4,), adjusted R^2 is 0.133189\n",
      "evaluating model with inputs (5,), adjusted R^2 is 0.026255\n",
      "evaluating model with inputs (6,), adjusted R^2 is 0.027027\n",
      "evaluating model with inputs (7,), adjusted R^2 is 0.107293\n",
      "evaluating model with inputs (0, 1), adjusted R^2 is 0.326471\n",
      "evaluating model with inputs (0, 2), adjusted R^2 is 0.256471\n",
      "evaluating model with inputs (0, 3), adjusted R^2 is 0.308919\n",
      "evaluating model with inputs (0, 4), adjusted R^2 is 0.349810\n",
      "evaluating model with inputs (0, 5), adjusted R^2 is 0.258752\n",
      "evaluating model with inputs (0, 6), adjusted R^2 is 0.249723\n",
      "evaluating model with inputs (0, 7), adjusted R^2 is 0.330087\n",
      "evaluating model with inputs (1, 2), adjusted R^2 is 0.020585\n",
      "evaluating model with inputs (1, 3), adjusted R^2 is 0.109988\n",
      "evaluating model with inputs (1, 4), adjusted R^2 is 0.146547\n",
      "evaluating model with inputs (1, 5), adjusted R^2 is 0.033744\n",
      "evaluating model with inputs (1, 6), adjusted R^2 is 0.034455\n",
      "evaluating model with inputs (1, 7), adjusted R^2 is 0.128824\n",
      "evaluating model with inputs (2, 3), adjusted R^2 is 0.116928\n",
      "evaluating model with inputs (2, 4), adjusted R^2 is 0.201842\n",
      "evaluating model with inputs (2, 5), adjusted R^2 is 0.036865\n",
      "evaluating model with inputs (2, 6), adjusted R^2 is 0.034711\n",
      "evaluating model with inputs (2, 7), adjusted R^2 is 0.109526\n",
      "evaluating model with inputs (3, 4), adjusted R^2 is 0.136567\n",
      "evaluating model with inputs (3, 5), adjusted R^2 is 0.131223\n",
      "evaluating model with inputs (3, 6), adjusted R^2 is 0.193561\n",
      "evaluating model with inputs (3, 7), adjusted R^2 is 0.263938\n",
      "evaluating model with inputs (4, 5), adjusted R^2 is 0.137248\n",
      "evaluating model with inputs (4, 6), adjusted R^2 is 0.197548\n",
      "evaluating model with inputs (4, 7), adjusted R^2 is 0.298366\n",
      "evaluating model with inputs (5, 6), adjusted R^2 is 0.065345\n",
      "evaluating model with inputs (5, 7), adjusted R^2 is 0.133351\n",
      "evaluating model with inputs (6, 7), adjusted R^2 is 0.120222\n",
      "evaluating model with inputs (0, 1, 2), adjusted R^2 is 0.401378\n",
      "evaluating model with inputs (0, 1, 3), adjusted R^2 is 0.402197\n",
      "evaluating model with inputs (0, 1, 4), adjusted R^2 is 0.417124\n",
      "evaluating model with inputs (0, 1, 5), adjusted R^2 is 0.326188\n",
      "evaluating model with inputs (0, 1, 6), adjusted R^2 is 0.328224\n",
      "evaluating model with inputs (0, 1, 7), adjusted R^2 is 0.413409\n",
      "evaluating model with inputs (0, 2, 3), adjusted R^2 is 0.308752\n",
      "evaluating model with inputs (0, 2, 4), adjusted R^2 is 0.351763\n",
      "evaluating model with inputs (0, 2, 5), adjusted R^2 is 0.266899\n",
      "evaluating model with inputs (0, 2, 6), adjusted R^2 is 0.258978\n",
      "evaluating model with inputs (0, 2, 7), adjusted R^2 is 0.349131\n",
      "evaluating model with inputs (0, 3, 4), adjusted R^2 is 0.351906\n",
      "evaluating model with inputs (0, 3, 5), adjusted R^2 is 0.334708\n",
      "evaluating model with inputs (0, 3, 6), adjusted R^2 is 0.349838\n",
      "evaluating model with inputs (0, 3, 7), adjusted R^2 is 0.450262\n",
      "evaluating model with inputs (0, 4, 5), adjusted R^2 is 0.350018\n",
      "evaluating model with inputs (0, 4, 6), adjusted R^2 is 0.369647\n",
      "evaluating model with inputs (0, 4, 7), adjusted R^2 is 0.480133\n",
      "evaluating model with inputs (0, 5, 6), adjusted R^2 is 0.264927\n",
      "evaluating model with inputs (0, 5, 7), adjusted R^2 is 0.342216\n",
      "evaluating model with inputs (0, 6, 7), adjusted R^2 is 0.329724\n",
      "evaluating model with inputs (1, 2, 3), adjusted R^2 is 0.129333\n",
      "evaluating model with inputs (1, 2, 4), adjusted R^2 is 0.201640\n",
      "evaluating model with inputs (1, 2, 5), adjusted R^2 is 0.039383\n",
      "evaluating model with inputs (1, 2, 6), adjusted R^2 is 0.038077\n",
      "evaluating model with inputs (1, 2, 7), adjusted R^2 is 0.128010\n",
      "evaluating model with inputs (1, 3, 4), adjusted R^2 is 0.153453\n",
      "evaluating model with inputs (1, 3, 5), adjusted R^2 is 0.142755\n",
      "evaluating model with inputs (1, 3, 6), adjusted R^2 is 0.199534\n",
      "evaluating model with inputs (1, 3, 7), adjusted R^2 is 0.303530\n",
      "evaluating model with inputs (1, 4, 5), adjusted R^2 is 0.147149\n",
      "evaluating model with inputs (1, 4, 6), adjusted R^2 is 0.198782\n",
      "evaluating model with inputs (1, 4, 7), adjusted R^2 is 0.315704\n",
      "evaluating model with inputs (1, 5, 6), adjusted R^2 is 0.064956\n",
      "evaluating model with inputs (1, 5, 7), adjusted R^2 is 0.144059\n",
      "evaluating model with inputs (1, 6, 7), adjusted R^2 is 0.133921\n",
      "evaluating model with inputs (2, 3, 4), adjusted R^2 is 0.205743\n",
      "evaluating model with inputs (2, 3, 5), adjusted R^2 is 0.170519\n",
      "evaluating model with inputs (2, 3, 6), adjusted R^2 is 0.233236\n",
      "evaluating model with inputs (2, 3, 7), adjusted R^2 is 0.285476\n",
      "evaluating model with inputs (2, 4, 5), adjusted R^2 is 0.202960\n",
      "evaluating model with inputs (2, 4, 6), adjusted R^2 is 0.267064\n",
      "evaluating model with inputs (2, 4, 7), adjusted R^2 is 0.349687\n",
      "evaluating model with inputs (2, 5, 6), adjusted R^2 is 0.072919\n",
      "evaluating model with inputs (2, 5, 7), adjusted R^2 is 0.135809\n",
      "evaluating model with inputs (2, 6, 7), adjusted R^2 is 0.121784\n",
      "evaluating model with inputs (3, 4, 5), adjusted R^2 is 0.149468\n",
      "evaluating model with inputs (3, 4, 6), adjusted R^2 is 0.232007\n",
      "evaluating model with inputs (3, 4, 7), adjusted R^2 is 0.320604\n",
      "evaluating model with inputs (3, 5, 6), adjusted R^2 is 0.305753\n",
      "evaluating model with inputs (3, 5, 7), adjusted R^2 is 0.322546\n",
      "evaluating model with inputs (3, 6, 7), adjusted R^2 is 0.364868\n",
      "evaluating model with inputs (4, 5, 6), adjusted R^2 is 0.207441\n",
      "evaluating model with inputs (4, 5, 7), adjusted R^2 is 0.299865\n",
      "evaluating model with inputs (4, 6, 7), adjusted R^2 is 0.341237\n",
      "evaluating model with inputs (5, 6, 7), adjusted R^2 is 0.154931\n",
      "evaluating model with inputs (0, 1, 2, 3), adjusted R^2 is 0.440853\n",
      "evaluating model with inputs (0, 1, 2, 4), adjusted R^2 is 0.432683\n",
      "evaluating model with inputs (0, 1, 2, 5), adjusted R^2 is 0.403953\n",
      "evaluating model with inputs (0, 1, 2, 6), adjusted R^2 is 0.414446\n",
      "evaluating model with inputs (0, 1, 2, 7), adjusted R^2 is 0.520822\n",
      "evaluating model with inputs (0, 1, 3, 4), adjusted R^2 is 0.426731\n",
      "evaluating model with inputs (0, 1, 3, 5), adjusted R^2 is 0.406315\n",
      "evaluating model with inputs (0, 1, 3, 6), adjusted R^2 is 0.411099\n",
      "evaluating model with inputs (0, 1, 3, 7), adjusted R^2 is 0.556023\n",
      "evaluating model with inputs (0, 1, 4, 5), adjusted R^2 is 0.419916\n",
      "evaluating model with inputs (0, 1, 4, 6), adjusted R^2 is 0.418405\n",
      "evaluating model with inputs (0, 1, 4, 7), adjusted R^2 is 0.549222\n",
      "evaluating model with inputs (0, 1, 5, 6), adjusted R^2 is 0.327570\n",
      "evaluating model with inputs (0, 1, 5, 7), adjusted R^2 is 0.413193\n",
      "evaluating model with inputs (0, 1, 6, 7), adjusted R^2 is 0.422476\n",
      "evaluating model with inputs (0, 2, 3, 4), adjusted R^2 is 0.354023\n",
      "evaluating model with inputs (0, 2, 3, 5), adjusted R^2 is 0.334062\n",
      "evaluating model with inputs (0, 2, 3, 6), adjusted R^2 is 0.349525\n",
      "evaluating model with inputs (0, 2, 3, 7), adjusted R^2 is 0.451344\n",
      "evaluating model with inputs (0, 2, 4, 5), adjusted R^2 is 0.351787\n",
      "evaluating model with inputs (0, 2, 4, 6), adjusted R^2 is 0.374250\n",
      "evaluating model with inputs (0, 2, 4, 7), adjusted R^2 is 0.480758\n",
      "evaluating model with inputs (0, 2, 5, 6), adjusted R^2 is 0.272731\n",
      "evaluating model with inputs (0, 2, 5, 7), adjusted R^2 is 0.359542\n",
      "evaluating model with inputs (0, 2, 6, 7), adjusted R^2 is 0.348660\n",
      "evaluating model with inputs (0, 3, 4, 5), adjusted R^2 is 0.355289\n",
      "evaluating model with inputs (0, 3, 4, 6), adjusted R^2 is 0.385229\n",
      "evaluating model with inputs (0, 3, 4, 7), adjusted R^2 is 0.496646\n",
      "evaluating model with inputs (0, 3, 5, 6), adjusted R^2 is 0.412002\n",
      "evaluating model with inputs (0, 3, 5, 7), adjusted R^2 is 0.484962\n",
      "evaluating model with inputs (0, 3, 6, 7), adjusted R^2 is 0.490668\n",
      "evaluating model with inputs (0, 4, 5, 6), adjusted R^2 is 0.371713\n",
      "evaluating model with inputs (0, 4, 5, 7), adjusted R^2 is 0.479755\n",
      "evaluating model with inputs (0, 4, 6, 7), adjusted R^2 is 0.491461\n",
      "evaluating model with inputs (0, 5, 6, 7), adjusted R^2 is 0.343320\n",
      "evaluating model with inputs (1, 2, 3, 4), adjusted R^2 is 0.206384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating model with inputs (1, 2, 3, 5), adjusted R^2 is 0.171863\n",
      "evaluating model with inputs (1, 2, 3, 6), adjusted R^2 is 0.232761\n",
      "evaluating model with inputs (1, 2, 3, 7), adjusted R^2 is 0.310986\n",
      "evaluating model with inputs (1, 2, 4, 5), adjusted R^2 is 0.202349\n",
      "evaluating model with inputs (1, 2, 4, 6), adjusted R^2 is 0.270260\n",
      "evaluating model with inputs (1, 2, 4, 7), adjusted R^2 is 0.351878\n",
      "evaluating model with inputs (1, 2, 5, 6), adjusted R^2 is 0.072088\n",
      "evaluating model with inputs (1, 2, 5, 7), adjusted R^2 is 0.143664\n",
      "evaluating model with inputs (1, 2, 6, 7), adjusted R^2 is 0.133167\n",
      "evaluating model with inputs (1, 3, 4, 5), adjusted R^2 is 0.160621\n",
      "evaluating model with inputs (1, 3, 4, 6), adjusted R^2 is 0.234537\n",
      "evaluating model with inputs (1, 3, 4, 7), adjusted R^2 is 0.347663\n",
      "evaluating model with inputs (1, 3, 5, 6), adjusted R^2 is 0.307436\n",
      "evaluating model with inputs (1, 3, 5, 7), adjusted R^2 is 0.341700\n",
      "evaluating model with inputs (1, 3, 6, 7), adjusted R^2 is 0.378694\n",
      "evaluating model with inputs (1, 4, 5, 6), adjusted R^2 is 0.206778\n",
      "evaluating model with inputs (1, 4, 5, 7), adjusted R^2 is 0.315112\n",
      "evaluating model with inputs (1, 4, 6, 7), adjusted R^2 is 0.346074\n",
      "evaluating model with inputs (1, 5, 6, 7), adjusted R^2 is 0.157334\n",
      "evaluating model with inputs (2, 3, 4, 5), adjusted R^2 is 0.212872\n",
      "evaluating model with inputs (2, 3, 4, 6), adjusted R^2 is 0.303305\n",
      "evaluating model with inputs (2, 3, 4, 7), adjusted R^2 is 0.371609\n",
      "evaluating model with inputs (2, 3, 5, 6), adjusted R^2 is 0.356809\n",
      "evaluating model with inputs (2, 3, 5, 7), adjusted R^2 is 0.348474\n",
      "evaluating model with inputs (2, 3, 6, 7), adjusted R^2 is 0.391184\n",
      "evaluating model with inputs (2, 4, 5, 6), adjusted R^2 is 0.272252\n",
      "evaluating model with inputs (2, 4, 5, 7), adjusted R^2 is 0.349667\n",
      "evaluating model with inputs (2, 4, 6, 7), adjusted R^2 is 0.394221\n",
      "evaluating model with inputs (2, 5, 6, 7), adjusted R^2 is 0.156536\n",
      "evaluating model with inputs (3, 4, 5, 6), adjusted R^2 is 0.305082\n",
      "evaluating model with inputs (3, 4, 5, 7), adjusted R^2 is 0.339308\n",
      "evaluating model with inputs (3, 4, 6, 7), adjusted R^2 is 0.406580\n",
      "evaluating model with inputs (3, 5, 6, 7), adjusted R^2 is 0.489450\n",
      "evaluating model with inputs (4, 5, 6, 7), adjusted R^2 is 0.346309\n",
      "evaluating model with inputs (0, 1, 2, 3, 4), adjusted R^2 is 0.445067\n",
      "evaluating model with inputs (0, 1, 2, 3, 5), adjusted R^2 is 0.440307\n",
      "evaluating model with inputs (0, 1, 2, 3, 6), adjusted R^2 is 0.440338\n",
      "evaluating model with inputs (0, 1, 2, 3, 7), adjusted R^2 is 0.609063\n",
      "evaluating model with inputs (0, 1, 2, 4, 5), adjusted R^2 is 0.438391\n",
      "evaluating model with inputs (0, 1, 2, 4, 6), adjusted R^2 is 0.432766\n",
      "evaluating model with inputs (0, 1, 2, 4, 7), adjusted R^2 is 0.571613\n",
      "evaluating model with inputs (0, 1, 2, 5, 6), adjusted R^2 is 0.429591\n",
      "evaluating model with inputs (0, 1, 2, 5, 7), adjusted R^2 is 0.525686\n",
      "evaluating model with inputs (0, 1, 2, 6, 7), adjusted R^2 is 0.557819\n",
      "evaluating model with inputs (0, 1, 3, 4, 5), adjusted R^2 is 0.426312\n",
      "evaluating model with inputs (0, 1, 3, 4, 6), adjusted R^2 is 0.434534\n",
      "evaluating model with inputs (0, 1, 3, 4, 7), adjusted R^2 is 0.582181\n",
      "evaluating model with inputs (0, 1, 3, 5, 6), adjusted R^2 is 0.430871\n",
      "evaluating model with inputs (0, 1, 3, 5, 7), adjusted R^2 is 0.563531\n",
      "evaluating model with inputs (0, 1, 3, 6, 7), adjusted R^2 is 0.563275\n",
      "evaluating model with inputs (0, 1, 4, 5, 6), adjusted R^2 is 0.420003\n",
      "evaluating model with inputs (0, 1, 4, 5, 7), adjusted R^2 is 0.554860\n",
      "evaluating model with inputs (0, 1, 4, 6, 7), adjusted R^2 is 0.548794\n",
      "evaluating model with inputs (0, 1, 5, 6, 7), adjusted R^2 is 0.422310\n",
      "evaluating model with inputs (0, 2, 3, 4, 5), adjusted R^2 is 0.357024\n",
      "evaluating model with inputs (0, 2, 3, 4, 6), adjusted R^2 is 0.391995\n",
      "evaluating model with inputs (0, 2, 3, 4, 7), adjusted R^2 is 0.497467\n",
      "evaluating model with inputs (0, 2, 3, 5, 6), adjusted R^2 is 0.416858\n",
      "evaluating model with inputs (0, 2, 3, 5, 7), adjusted R^2 is 0.484739\n",
      "evaluating model with inputs (0, 2, 3, 6, 7), adjusted R^2 is 0.490171\n",
      "evaluating model with inputs (0, 2, 4, 5, 6), adjusted R^2 is 0.375987\n",
      "evaluating model with inputs (0, 2, 4, 5, 7), adjusted R^2 is 0.480335\n",
      "evaluating model with inputs (0, 2, 4, 6, 7), adjusted R^2 is 0.493513\n",
      "evaluating model with inputs (0, 2, 5, 6, 7), adjusted R^2 is 0.360214\n",
      "evaluating model with inputs (0, 3, 4, 5, 6), adjusted R^2 is 0.413991\n",
      "evaluating model with inputs (0, 3, 4, 5, 7), adjusted R^2 is 0.503907\n",
      "evaluating model with inputs (0, 3, 4, 6, 7), adjusted R^2 is 0.529234\n",
      "evaluating model with inputs (0, 3, 5, 6, 7), adjusted R^2 is 0.566850\n",
      "evaluating model with inputs (0, 4, 5, 6, 7), adjusted R^2 is 0.491815\n",
      "evaluating model with inputs (1, 2, 3, 4, 5), adjusted R^2 is 0.212508\n",
      "evaluating model with inputs (1, 2, 3, 4, 6), adjusted R^2 is 0.305168\n",
      "evaluating model with inputs (1, 2, 3, 4, 7), adjusted R^2 is 0.378483\n",
      "evaluating model with inputs (1, 2, 3, 5, 6), adjusted R^2 is 0.378427\n",
      "evaluating model with inputs (1, 2, 3, 5, 7), adjusted R^2 is 0.355947\n",
      "evaluating model with inputs (1, 2, 3, 6, 7), adjusted R^2 is 0.395236\n",
      "evaluating model with inputs (1, 2, 4, 5, 6), adjusted R^2 is 0.280148\n",
      "evaluating model with inputs (1, 2, 4, 5, 7), adjusted R^2 is 0.351362\n",
      "evaluating model with inputs (1, 2, 4, 6, 7), adjusted R^2 is 0.394005\n",
      "evaluating model with inputs (1, 2, 5, 6, 7), adjusted R^2 is 0.157475\n",
      "evaluating model with inputs (1, 3, 4, 5, 6), adjusted R^2 is 0.306773\n",
      "evaluating model with inputs (1, 3, 4, 5, 7), adjusted R^2 is 0.357967\n",
      "evaluating model with inputs (1, 3, 4, 6, 7), adjusted R^2 is 0.414987\n",
      "evaluating model with inputs (1, 3, 5, 6, 7), adjusted R^2 is 0.489149\n",
      "evaluating model with inputs (1, 4, 5, 6, 7), adjusted R^2 is 0.348273\n",
      "evaluating model with inputs (2, 3, 4, 5, 6), adjusted R^2 is 0.361486\n",
      "evaluating model with inputs (2, 3, 4, 5, 7), adjusted R^2 is 0.383987\n",
      "evaluating model with inputs (2, 3, 4, 6, 7), adjusted R^2 is 0.459792\n",
      "evaluating model with inputs (2, 3, 5, 6, 7), adjusted R^2 is 0.525197\n",
      "evaluating model with inputs (2, 4, 5, 6, 7), adjusted R^2 is 0.396519\n",
      "evaluating model with inputs (3, 4, 5, 6, 7), adjusted R^2 is 0.488952\n",
      "evaluating model with inputs (0, 1, 2, 3, 4, 5), adjusted R^2 is 0.445412\n",
      "evaluating model with inputs (0, 1, 2, 3, 4, 6), adjusted R^2 is 0.445095\n",
      "evaluating model with inputs (0, 1, 2, 3, 4, 7), adjusted R^2 is 0.611711\n",
      "evaluating model with inputs (0, 1, 2, 3, 5, 6), adjusted R^2 is 0.439875\n",
      "evaluating model with inputs (0, 1, 2, 3, 5, 7), adjusted R^2 is 0.608795\n",
      "evaluating model with inputs (0, 1, 2, 3, 6, 7), adjusted R^2 is 0.609253\n",
      "evaluating model with inputs (0, 1, 2, 4, 5, 6), adjusted R^2 is 0.442994\n",
      "evaluating model with inputs (0, 1, 2, 4, 5, 7), adjusted R^2 is 0.582001\n",
      "evaluating model with inputs (0, 1, 2, 4, 6, 7), adjusted R^2 is 0.578959\n",
      "evaluating model with inputs (0, 1, 2, 5, 6, 7), adjusted R^2 is 0.594312\n",
      "evaluating model with inputs (0, 1, 3, 4, 5, 6), adjusted R^2 is 0.437624\n",
      "evaluating model with inputs (0, 1, 3, 4, 5, 7), adjusted R^2 is 0.581857\n",
      "evaluating model with inputs (0, 1, 3, 4, 6, 7), adjusted R^2 is 0.588412\n",
      "evaluating model with inputs (0, 1, 3, 5, 6, 7), adjusted R^2 is 0.588679\n",
      "evaluating model with inputs (0, 1, 4, 5, 6, 7), adjusted R^2 is 0.554995\n",
      "evaluating model with inputs (0, 2, 3, 4, 5, 6), adjusted R^2 is 0.421509\n",
      "evaluating model with inputs (0, 2, 3, 4, 5, 7), adjusted R^2 is 0.504358\n",
      "evaluating model with inputs (0, 2, 3, 4, 6, 7), adjusted R^2 is 0.533539\n",
      "evaluating model with inputs (0, 2, 3, 5, 6, 7), adjusted R^2 is 0.570022\n",
      "evaluating model with inputs (0, 2, 4, 5, 6, 7), adjusted R^2 is 0.493748\n",
      "evaluating model with inputs (0, 3, 4, 5, 6, 7), adjusted R^2 is 0.568096\n",
      "evaluating model with inputs (1, 2, 3, 4, 5, 6), adjusted R^2 is 0.382944\n",
      "evaluating model with inputs (1, 2, 3, 4, 5, 7), adjusted R^2 is 0.387670\n",
      "evaluating model with inputs (1, 2, 3, 4, 6, 7), adjusted R^2 is 0.459272\n",
      "evaluating model with inputs (1, 2, 3, 5, 6, 7), adjusted R^2 is 0.534423\n",
      "evaluating model with inputs (1, 2, 4, 5, 6, 7), adjusted R^2 is 0.397521\n",
      "evaluating model with inputs (1, 3, 4, 5, 6, 7), adjusted R^2 is 0.488656\n",
      "evaluating model with inputs (2, 3, 4, 5, 6, 7), adjusted R^2 is 0.528144\n",
      "evaluating model with inputs (0, 1, 2, 3, 4, 5, 6), adjusted R^2 is 0.444872\n",
      "evaluating model with inputs (0, 1, 2, 3, 4, 5, 7), adjusted R^2 is 0.611486\n",
      "evaluating model with inputs (0, 1, 2, 3, 4, 6, 7), adjusted R^2 is 0.611434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating model with inputs (0, 1, 2, 3, 5, 6, 7), adjusted R^2 is 0.609163\n",
      "evaluating model with inputs (0, 1, 2, 4, 5, 6, 7), adjusted R^2 is 0.607525\n",
      "evaluating model with inputs (0, 1, 3, 4, 5, 6, 7), adjusted R^2 is 0.594314\n",
      "evaluating model with inputs (0, 2, 3, 4, 5, 6, 7), adjusted R^2 is 0.573028\n",
      "evaluating model with inputs (1, 2, 3, 4, 5, 6, 7), adjusted R^2 is 0.537334\n",
      "evaluating model with inputs (0, 1, 2, 3, 4, 5, 6, 7), adjusted R^2 is 0.612452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0, 1, 2, 3, 4, 5, 6, 7), 0.61245172533057224)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(HTML(\"<h2>Best Subsets\"))\n",
    "display(HTML(\"<a href='http://songhuiming.github.io/pages/2015/09/26/best-subset-regression-in-python/'>Source</a>\"))\n",
    "#this code required extensive modifications\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain, combinations\n",
    "import statsmodels.formula.api as sm\n",
    "import statsmodels.tools.tools as smt\n",
    "# xrange is a Python 2 construct not defined in Python 3\n",
    "def xrange(x):\n",
    "    return iter(range(x))\n",
    "def best_subset(X, y):\n",
    "    n_features = X.shape[1]\n",
    "    subsets = chain.from_iterable(combinations(xrange(n_features), k+1) for k in xrange(n_features))\n",
    "    best_score = -np.inf\n",
    "    best_subset = None\n",
    "    for subset in subsets:\n",
    "        subsetArray=np.array(subset)\n",
    "        tmpX=smt.add_constant(X.iloc[:,subsetArray])\n",
    "        lin_reg = sm.OLS(y,tmpX).fit()\n",
    "        score = lin_reg.rsquared_adj\n",
    "        print(\"evaluating model with inputs %s, adjusted R^2 is %f\"%(subset,score))\n",
    "        #print(lin_reg.summary())\n",
    "        if score > best_score:\n",
    "            best_score, best_subset = score, subset\n",
    "    return best_subset, best_score\n",
    "X=df.drop('strength',axis=1)\n",
    "#print(X.head(5))\n",
    "best_subset(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Example 9\n",
    "\n",
    "## Principal Components as Predictors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Standardization</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2> Cumulative Percent variability explained by each component"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.28498605  0.46201247  0.62954284  0.75631214  0.87526237  0.97402864\n",
      "  0.99624471  1.        ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1>Scree Plot using Python</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWlsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c82bbce3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "display(HTML(\"<h1>Standardization</h1>\"))\n",
    "std_scaler=preprocessing.StandardScaler().fit(exog1.values)\n",
    "df_scaled=std_scaler.transform(exog1)\n",
    "df_scaled_df=pd.DataFrame(df_scaled,index=exog1.index,columns=exog1.columns)\n",
    "# execute first pca\n",
    "pca=decomposition.PCA(n_components=8)\n",
    "pca.fit(df_scaled_df)\n",
    "#display cumulative sum of variability explained\n",
    "display(HTML(\"<h2> Cumulative Percent variability explained by each component\"))\n",
    "print(np.cumsum(pca.explained_variance_ratio_))\n",
    "display(HTML(\"<h1>Scree Plot using Python</h1>\"))\n",
    "plt.plot(np.arange(1,9,1),pca.explained_variance_,'-bo')\n",
    "plt.show()\n",
    "#Use 6 principal components\n",
    "pca2=decomposition.PCA(n_components=6)\n",
    "pca2.fit(df_scaled_df)\n",
    "scaled_reduced=pca2.fit_transform(df_scaled_df)\n",
    "df_scaled_reduced=pd.DataFrame(scaled_reduced)\n",
    "df_scaled_reduced.columns=['PCA-1','PCA-2','PCA-3','PCA-4','PCA-5','PCA-6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>strength</td>     <th>  R-squared:         </th> <td>   0.101</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.096</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   19.15</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Feb 2018</td> <th>  Prob (F-statistic):</th> <td>3.13e-21</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:28:15</td>     <th>  Log-Likelihood:    </th> <td> -5193.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1030</td>      <th>  AIC:               </th> <td>1.040e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1024</td>      <th>  BIC:               </th> <td>1.043e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>   -0.5294</td> <td>    0.776</td> <td>   -0.683</td> <td> 0.495</td> <td>   -2.051</td> <td>    0.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>    2.4333</td> <td>    0.984</td> <td>    2.473</td> <td> 0.014</td> <td>    0.502</td> <td>    4.364</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>    7.9132</td> <td>    1.012</td> <td>    7.823</td> <td> 0.000</td> <td>    5.928</td> <td>    9.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th> <td>   -0.0036</td> <td>    1.163</td> <td>   -0.003</td> <td> 0.998</td> <td>   -2.285</td> <td>    2.278</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th> <td>    5.6093</td> <td>    1.200</td> <td>    4.673</td> <td> 0.000</td> <td>    3.254</td> <td>    7.965</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th> <td>    6.6243</td> <td>    1.317</td> <td>    5.028</td> <td> 0.000</td> <td>    4.039</td> <td>    9.209</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.079</td> <th>  Durbin-Watson:     </th> <td>   0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.961</td> <th>  Jarque-Bera (JB):  </th> <td>   0.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.014</td> <th>  Prob(JB):          </th> <td>   0.936</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.952</td> <th>  Cond. No.          </th> <td>    1.70</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               strength   R-squared:                       0.101\n",
       "Model:                            OLS   Adj. R-squared:                  0.096\n",
       "Method:                 Least Squares   F-statistic:                     19.15\n",
       "Date:                Mon, 19 Feb 2018   Prob (F-statistic):           3.13e-21\n",
       "Time:                        16:28:15   Log-Likelihood:                -5193.8\n",
       "No. Observations:                1030   AIC:                         1.040e+04\n",
       "Df Residuals:                    1024   BIC:                         1.043e+04\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.5294      0.776     -0.683      0.495      -2.051       0.992\n",
       "x2             2.4333      0.984      2.473      0.014       0.502       4.364\n",
       "x3             7.9132      1.012      7.823      0.000       5.928       9.898\n",
       "x4            -0.0036      1.163     -0.003      0.998      -2.285       2.278\n",
       "x5             5.6093      1.200      4.673      0.000       3.254       7.965\n",
       "x6             6.6243      1.317      5.028      0.000       4.039       9.209\n",
       "==============================================================================\n",
       "Omnibus:                        0.079   Durbin-Watson:                   0.113\n",
       "Prob(Omnibus):                  0.961   Jarque-Bera (JB):                0.133\n",
       "Skew:                          -0.014   Prob(JB):                        0.936\n",
       "Kurtosis:                       2.952   Cond. No.                         1.70\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_reg = sm.OLS(y,scaled_reduced).fit()\n",
    "pca_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "qc=pd.read_excel('OptimalEwma.xlsx', sheetname='Sheet1')\n",
    "qc=qc.dropna(axis=0,how='any')\n",
    "qc\n",
    "#\n",
    "fig=plt.figure()\n",
    "ax=fig.add_subplot(111,projection='3d')\n",
    "#ax.scatter(qc[' ARL_0'],[' Shift'],['Lambda'],'r','^')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
