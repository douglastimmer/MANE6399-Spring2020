{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANE 6399 - Data Science in Manufacturing\n",
    "## Homework 5 Assignment\n",
    "\n",
    "### Your Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['y', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6'], dtype='object')\n",
      "                 y           x1            x2           x3          x4  \\\n",
      "count    40.000000    40.000000     40.000000     40.00000   40.000000   \n",
      "mean   3904.000000  1809.925000  19494.600000  29605.77500  174.500000   \n",
      "std     504.646004   251.950482    940.944419    466.21776   23.436767   \n",
      "min    3045.000000  1388.000000  17780.000000  28675.00000  133.000000   \n",
      "25%    3517.500000  1607.750000  18880.000000  29302.50000  155.250000   \n",
      "50%    3977.000000  1849.500000  19765.000000  29745.00000  179.000000   \n",
      "75%    4332.500000  2023.750000  20286.250000  29960.00000  193.500000   \n",
      "max    4833.000000  2239.000000  20740.000000  30250.00000  216.000000   \n",
      "\n",
      "                x5          x6  \n",
      "count    40.000000   40.000000  \n",
      "mean   1651.900000   97.425000  \n",
      "std      68.895983    4.717059  \n",
      "min    1522.000000   85.000000  \n",
      "25%    1592.500000   97.000000  \n",
      "50%    1668.000000   99.000000  \n",
      "75%    1709.500000  100.000000  \n",
      "max    1758.000000  102.000000  \n"
     ]
    }
   ],
   "source": [
    "# Cell 2 - load data into dataframe df\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_excel('data-table-B13.XLS',sheet_name='Sheet1')\n",
    "print(df.columns)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fwn285\\AppData\\Local\\Continuum\\anaconda3\\envs\\env_iise\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    model  p    Mallows Cp  R-Squared_Adj   MSE-residual         AIC  \\\n",
      "0    (0,)  1  13955.072038       0.989783    2602.012505  430.024969   \n",
      "1    (1,)  1  13426.822329       0.951424   12370.688038  492.386754   \n",
      "2    (2,)  1  12154.581541       0.859041   35897.643657  535.000428   \n",
      "3    (3,)  1  13957.949673       0.989992    2548.797733  429.198433   \n",
      "4    (4,)  1  10701.520676       0.753528   62768.420628  557.351646   \n",
      "5    (5,)  1    269.250674      -0.004005  255687.524989  613.531806   \n",
      "6  (0, 1)  2  13965.599402       0.990143    2510.382639  429.524240   \n",
      "7  (0, 2)  2  13998.601196       0.992604    1883.601607  418.034260   \n",
      "8  (0, 3)  2  14000.878651       0.992774    1840.347427  417.105007   \n",
      "9  (0, 4)  2  13979.575934       0.991185    2244.935699  425.053907   \n",
      "\n",
      "          BIC  \n",
      "0  433.402728  \n",
      "1  495.764513  \n",
      "2  538.378187  \n",
      "3  432.576192  \n",
      "4  560.729405  \n",
      "5  616.909565  \n",
      "6  434.590878  \n",
      "7  423.100898  \n",
      "8  422.171645  \n",
      "9  430.120546  \n",
      "                 model  p    Mallows Cp  R-Squared_Adj  MSE-residual  \\\n",
      "53        (1, 2, 4, 5)  4  13966.605120       0.989343   2713.951085   \n",
      "54        (1, 3, 4, 5)  4  14045.871729       0.995592   1122.467183   \n",
      "55        (2, 3, 4, 5)  4  14053.365009       0.996183    972.020044   \n",
      "56     (0, 1, 2, 3, 4)  5  14028.944455       0.993927   1546.672215   \n",
      "57     (0, 1, 2, 3, 5)  5  14065.287733       0.996876    795.524775   \n",
      "58     (0, 1, 2, 4, 5)  5  14068.724474       0.997155    724.493767   \n",
      "59     (0, 1, 3, 4, 5)  5  14066.960373       0.997012    760.954427   \n",
      "60     (0, 2, 3, 4, 5)  5  14070.154900       0.997271    694.929550   \n",
      "61     (1, 2, 3, 4, 5)  5  14055.533211       0.996085    997.132452   \n",
      "62  (0, 1, 2, 3, 4, 5)  6  14072.778149       0.997241    702.716280   \n",
      "\n",
      "           AIC         BIC  \n",
      "53  434.420260  442.864657  \n",
      "54  399.105202  407.549600  \n",
      "55  393.348884  401.793281  \n",
      "56  412.768763  422.902040  \n",
      "57  386.174405  396.307682  \n",
      "58  382.433252  392.566529  \n",
      "59  384.397264  394.530541  \n",
      "60  380.766744  390.900021  \n",
      "61  395.209670  405.342947  \n",
      "62  382.018336  393.840492  \n",
      "Index(['x1', 'x2', 'x3', 'x4', 'x5', 'x6'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fwn285\\AppData\\Local\\Continuum\\anaconda3\\envs\\env_iise\\lib\\site-packages\\ipykernel_launcher.py:48: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3\n",
    "# Python code applying regressionDiagnostics function to the Jet Engine Thrust data\n",
    "#this code extends the Mallows CP example\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain, combinations\n",
    "import statsmodels.formula.api as sm\n",
    "import statsmodels.tools.tools as smt\n",
    "import matplotlib.pyplot as plt\n",
    "# xrange is a Python 2 construct not defined in Python 3\n",
    "def xrange(x):\n",
    "    return iter(range(x))\n",
    "def regressionDiagnostics(X, y):\n",
    "    n_features = X.shape[1]\n",
    "    subsets = chain.from_iterable(combinations(xrange(n_features), k+1) for k in xrange(n_features))\n",
    "    #find full model and perform regression\n",
    "    for subset in subsets:\n",
    "        foo=np.array(subset)\n",
    "        if foo.size == n_features:\n",
    "            tmpX=smt.add_constant(X.iloc[:,foo])\n",
    "            lin_reg_full=sm.OLS(y,tmpX).fit()\n",
    "            N=X.shape[0]\n",
    "            mse_full=lin_reg_full.mse_resid\n",
    "    # create arrays to hold results\n",
    "    modelArray=[]\n",
    "    cpArray=[]\n",
    "    pArray=[]\n",
    "    rSquaredAdj=[]\n",
    "    mse_res=[]\n",
    "    aicArray=[]\n",
    "    bicArray=[]\n",
    "    #process all models and store results\n",
    "    subsets = chain.from_iterable(combinations(xrange(n_features), k+1) for k in xrange(n_features))\n",
    "    for subset in subsets:\n",
    "        subsetArray=np.array(subset)\n",
    "        p=subsetArray.size\n",
    "        tmpX=smt.add_constant(X.iloc[:,subsetArray])\n",
    "        lin_reg = sm.OLS(y,tmpX).fit()\n",
    "        p=subsetArray.size\n",
    "        Cp=(lin_reg.ess/mse_full)-N+2.0*p\n",
    "        modelArray.append(subset)\n",
    "        cpArray.append(Cp)\n",
    "        pArray.append(p)\n",
    "        rSquaredAdj.append(lin_reg.rsquared_adj)\n",
    "        mse_res.append(lin_reg.mse_resid)\n",
    "        aicArray.append(lin_reg.aic)\n",
    "        bicArray.append(lin_reg.bic)\n",
    "    cp_df=pd.DataFrame.from_items([('model',modelArray),('p',pArray),('Mallows Cp',cpArray),('R-Squared_Adj',rSquaredAdj),('MSE-residual',mse_res),('AIC',aicArray),('BIC',bicArray)])\n",
    "    return cp_df\n",
    "X=df.drop('y',axis=1)\n",
    "y=df[\"y\"]\n",
    "#print(X.head(5))\n",
    "allDiagnostics=regressionDiagnostics(X,y)\n",
    "print(allDiagnostics.head(10))\n",
    "print(allDiagnostics.tail(10))\n",
    "#\n",
    "print(X.columns)\n",
    "#save to excel file\n",
    "writer=pd.ExcelWriter('AllDiagnostics2.xlsx','xlsxwriter')\n",
    "allDiagnostics.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 4\n",
    ">  Interpret the output of the regressionDiagnostics function. Your answer should include an optimal model for each criterion. From the pool of best models select an overall best model and explain why you selected that model\n",
    "\n",
    "The interpretation of the regressionDiagnostics data is best performed in Excel. There were five different criterion evaluated: Mallow's Cp, adjusted R^2, MSE-residual, AIC and BIC. Overall Mallow's Cp did not perform well. It indicated the best model was (5) which actually had a negative adjusted R^2 value.\n",
    "\n",
    "Three of the criterion (adjusted R^2, MSE-residual, and AIC) picked the same model (0,2,3,4,5). The remaining criterion, BIC, selected the model (0,2,4,5). The difference in the two models is neglible and either model is satisfactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The neural network trained for 32 epochs\n",
      "R^2 value for the training set is -0.877047\n",
      "R^2 value for the test set is -0.457386\n",
      "MSE for training: 425144.31\n",
      "MSE for test: 451988.95\n",
      "Mean absolute error for training: 510.79\n",
      "Mean absolute error for test: 484.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fwn285\\AppData\\Local\\Continuum\\anaconda3\\envs\\env_iise\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\fwn285\\AppData\\Local\\Continuum\\anaconda3\\envs\\env_iise\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5\n",
    "#\n",
    "# Cell 9 - Neural network code\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#build the data arrays and scale\n",
    "qcX=df.drop(df.columns[[0]],axis=1)\n",
    "#print(qcX)\n",
    "qcY=df.drop(df.columns[[1,2,3,4,5,6]],axis=1)\n",
    "#print(qcY)\n",
    "qc_scaler=MinMaxScaler()\n",
    "X_scaled=qc_scaler.fit_transform(qcX,qcY)\n",
    "qcX_train,qcX_test,qcY_train,qcY_test=train_test_split(X_scaled,qcY,test_size=0.25)\n",
    "#create dataframes for training and testing datasets\n",
    "foo={'x1':qcX_train[:,0],'x2':qcX_train[:,1],'x3':qcX_train[:,2],'x4':qcX_train[:,3],'x5':qcX_train[:,4],'x6':qcX_train[:,5]} \n",
    "nn1_train_df=pd.DataFrame(data=foo)\n",
    "nn1_train_df['y']=qcY_train.values[:,0]\n",
    "#print(nn1_train_df)\n",
    "foo={'x1':qcX_test[:,0],'x2':qcX_test[:,1],'x3':qcX_test[:,2],'x4':qcX_test[:,3],'x5':qcX_test[:,4],'x6':qcX_test[:,5]} \n",
    "nn1_test_df=pd.DataFrame(data=foo)\n",
    "nn1_test_df['y']=qcY_test.values[:,0]\n",
    "#print(nn1_test_df)\n",
    "# fit the neural network model\n",
    "nn1=MLPRegressor(hidden_layer_sizes=(15,),\n",
    "                activation='logistic',\n",
    "                solver='sgd',\n",
    "                max_iter=5000,\n",
    "                early_stopping=True)\n",
    "nn1.fit(qcX_train,qcY_train)\n",
    "\n",
    "#\n",
    "nn1_train_pred=nn1.predict(qcX_train)\n",
    "nn1_train_df['Pred_y']=nn1_train_pred[:]\n",
    "nn1_train_df['resid_y']=nn1_train_df['y']-nn1_train_df['Pred_y']\n",
    "#\n",
    "nn1_test_pred=nn1.predict(qcX_test)\n",
    "nn1_test_df['Pred_y']=nn1_test_pred[:]\n",
    "nn1_test_df['resid_y']=nn1_test_df['y']-nn1_test_df['Pred_y']\n",
    "#\n",
    "# report R2 values\n",
    "print(\"The neural network trained for %d epochs\"%(nn1.n_iter_))\n",
    "print(\"R^2 value for the training set is %f\"%(nn1.score(qcX_train,qcY_train)))\n",
    "print(\"R^2 value for the test set is %f\"%(nn1.score(qcX_test,qcY_test)))\n",
    "print(\"MSE for training: %.2f\"% np.mean((nn1_train_df['resid_y']) ** 2))\n",
    "print(\"MSE for test: %.2f\"% np.mean((nn1_test_df['resid_y']) ** 2))\n",
    "print(\"Mean absolute error for training: %.2f\"%mean_absolute_error(nn1_train_df['y'],nn1_train_df['Pred_y']))\n",
    "print(\"Mean absolute error for test: %.2f\"%mean_absolute_error(nn1_test_df['y'],nn1_test_df['Pred_y']))\n",
    "\n",
    "#fig=plt.figure(figsize=(20,8))\n",
    "#ig.subplots_adjust(hspace=0.8, wspace=0.8)\n",
    "#ax=fig.add_subplot(131,projection='3d')\n",
    "#ax.scatter(nn1_train_df['ARL_0'],nn1_train_df['Shift'],nn1_train_df['resid_Lambda'])\n",
    "#ax.set_xlabel('ARL_0')\n",
    "#ax.set_ylabel('Shift')\n",
    "#ax.set_zlabel('residual-Lambda')\n",
    "#\n",
    "#ax=fig.add_subplot(132,projection='3d')\n",
    "#ax.scatter(nn1_train_df['ARL_0'],nn1_train_df['Shift'],nn1_train_df['resid_H'])\n",
    "#ax.set_xlabel('ARL_0')\n",
    "#ax.set_ylabel('Shift')\n",
    "#ax.set_zlabel('residual-H')\n",
    "#\n",
    "#ax=fig.add_subplot(133,projection='3d')\n",
    "#ax.scatter(nn1_train_df['ARL_0'],nn1_train_df['Shift'],nn1_train_df['resid_ARL1'])\n",
    "#ax.set_xlabel('ARL_0')\n",
    "#ax.set_ylabel('Shift')\n",
    "#ax.set_zlabel('residual-ARL1')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 6\n",
    "> State whether you would recommend the neural network model or the multiple regresson model. What is the basis for your decision? In other words, explain why you made your decision\n",
    "\n",
    "This neural network performs very poorly on the same dataset that the regression diagnostics was applied to. Notice the negative R^2 scores for the neural network (this requires more investigation; unfortunately, I don't have the time). The MSE-residual was 425144.31 for the training set compared to the best MSE-residual from the regression diagonstics of 694.930.\n",
    "\n",
    "The reason for the poor performance of this neural network is the configuration of the neural network. To get a much better neural network model, hypertuning of parameters must be implemented. Unfortunately, I did not have the time to try and build the best neural network model possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
